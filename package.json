{
  "name": "layerganza",
  "version": "2.3.4",
  "description": "A feed-forward neural network with injectable layers, activation functions, and optimizers.",
  "main": "lib/index.js",
  "scripts": {
    "test": "./prepublish.bash;node ./runTests.js"
  },
  "babel": {
    "presets": [
      "es2015"
    ]
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/rodmcnew/layerganza.git"
  },
  "author": "Rod McNew",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/rodmcnew/layerganza/issues"
  },
  "homepage": "https://github.com/rodmcnew/layerganza#readme",
  "devDependencies": {
    "babel-cli": "^6.24.1",
    "babel-core": "^6.24.1",
    "babel-preset-es2015": "^6.24.1"
  },
  "keywords": [
    "deep",
    "learning",
    "neural",
    "network",
    "gradient",
    "desecent",
    "activation",
    "function",
    "relu",
    "backpropagation"
  ]
}
